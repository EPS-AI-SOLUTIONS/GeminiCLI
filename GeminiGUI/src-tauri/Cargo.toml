[package]
name = "geminigui"
version = "0.2.0"
description = "GeminiGUI - Tauri + React AI Chat Interface"
authors = ["GeminiCLI Team"]
edition = "2021"
rust-version = "1.75"

[lib]
name = "geminigui_lib"
crate-type = ["staticlib", "cdylib", "rlib"]

[build-dependencies]
tauri-build = { version = "2.0.0", features = [] }

[dependencies]
tauri = { version = "2.0.0", features = ["tray-icon"] }
tauri-plugin-opener = "2.0.0"
tauri-plugin-dialog = "2.0.0"
tauri-plugin-fs = "2.0.0"
serde = { version = "1.0.217", features = ["derive"] }
serde_json = "1.0.138"
reqwest = { version = "0.12.12", features = ["json", "rustls-tls", "stream"] }
tokio = { version = "1.43.0", features = ["rt", "rt-multi-thread", "fs", "io-util", "sync", "macros"] }
futures-util = "0.3.31"

# llama.cpp integration
llama-cpp-2 = "0.1"
hf-hub = "0.3"
once_cell = "1.19"
parking_lot = "0.12"
walkdir = "2.5"
bytesize = "1.3"
thiserror = "1.0"
tracing = "0.1"

[features]
default = ["cuda"]
cuda = ["llama-cpp-2/cuda"]
metal = ["llama-cpp-2/metal"]
vulkan = ["llama-cpp-2/vulkan"]

[profile.release]
lto = true
opt-level = 3
codegen-units = 1
panic = "abort"
strip = true

[profile.dev]
opt-level = 0
debug = true
