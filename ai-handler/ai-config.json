{
    "providers": {
        "google": {
            "name": "Google",
            "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
            "apiKeyEnv": "GOOGLE_API_KEY",
            "priority": 1,
            "enabled": true,
            "models": {
                "gemini-2.0-flash-exp": { "tokensPerMinute": 999999, "outputCost": 0, "capabilities": ["vision", "code", "analysis"], "tier": "standard", "contextWindow": 128000, "maxOutput": 8192 },
                "gemini-1.5-flash": { "tokensPerMinute": 999999, "outputCost": 0, "capabilities": ["vision", "code", "analysis"], "tier": "standard", "contextWindow": 128000, "maxOutput": 8192 },
                "gemini-2.5-flash": { "tokensPerMinute": 999999, "outputCost": 0, "capabilities": ["vision", "code", "analysis"], "tier": "standard", "contextWindow": 128000, "maxOutput": 8192 }
            }
        },
        "openai": {
            "name": "OpenAI",
            "baseUrl": "https://api.openai.com/v1",
            "apiKeyEnv": "OPENAI_API_KEY",
            "priority": 2,
            "enabled": true,
            "models": {
                "gpt-4o": { "tokensPerMinute": 999999, "outputCost": 10, "capabilities": ["vision", "code", "analysis"], "tier": "pro", "contextWindow": 128000, "maxOutput": 16384 },
                "gpt-4o-mini": { "tokensPerMinute": 999999, "outputCost": 0.6, "capabilities": ["code", "analysis"], "tier": "lite", "contextWindow": 128000, "maxOutput": 16384 }
            }
        },
        "anthropic": {
            "name": "Anthropic",
            "baseUrl": "https://api.anthropic.com/v1",
            "apiKeyEnv": "ANTHROPIC_API_KEY",
            "priority": 3,
            "enabled": true,
            "models": {
                "claude-3-5-sonnet-20241022": { "tokensPerMinute": 999999, "outputCost": 15, "capabilities": ["vision", "code", "analysis"], "tier": "standard", "contextWindow": 200000, "maxOutput": 8192 }
            }
        },
        "groq": {
            "name": "Groq",
            "baseUrl": "https://api.groq.com/openai/v1",
            "apiKeyEnv": "GROQ_API_KEY",
            "priority": 4,
            "enabled": true,
            "models": {
                "llama-3.1-8b-instant": { "tokensPerMinute": 999999, "outputCost": 0, "capabilities": ["code", "analysis"], "tier": "standard", "contextWindow": 128000, "maxOutput": 8192 }
            }
        },
        "ollama": {
            "name": "Ollama (Local)",
            "baseUrl": "http://localhost:11434/api",
            "apiKeyEnv": null,
            "priority": 6,
            "enabled": true,
            "models": {
                "llama3.2:3b": { "tokensPerMinute": 999999, "outputCost": 0, "capabilities": ["code", "analysis"], "tier": "lite", "contextWindow": 128000, "maxOutput": 4096 }
            }
        },
        "mistral": {
            "name": "Mistral",
            "baseUrl": "https://api.mistral.ai/v1",
            "apiKeyEnv": "MISTRAL_API_KEY",
            "priority": 5,
            "enabled": false,
            "models": {}
        }
    },
    "providerFallbackOrder": [
        "google",
        "openai",
        "anthropic",
        "groq",
        "mistral",
        "ollama"
    ],
    "settings": {
        "preferLocal": false,
        "costOptimization": false,
        "ollamaDefaultModel": "llama3.2:3b",
        "autoInstallOllama": true,
        "maxRetries": 5,
        "autoFallback": true,
        "logLevel": "info",
        "modelAliases": {
            "_comment": "Aliases resolved dynamically at runtime. null = dynamic (API query), string = static mapping",
            "gemini-pro-latest": null,
            "gemini-flash-latest": null,
            "gemini-pro-research": null,
            "gemini-flash-thinking": null,
            "gemini-pro-planning": null,
            "gemini-flash-fast": null,
            "claude-best": "claude-opus-4-5-20251101",
            "claude-balanced": "claude-sonnet-4-5-20250929",
            "claude-fast": "claude-haiku-4-20250604",
            "gpt-best": "gpt-4o",
            "gpt-fast": "gpt-4o-mini",
            "local-best": "llama3.2:3b",
            "local-coder": "qwen2.5-coder:1.5b",
            "local-fast": "llama3.2:1b",
            "local-analytical": "phi3:mini"
        },
        "aliasFallbackChains": {
            "_comment": "Fallback chains for each task type when primary alias fails",
            "planning": ["gemini-pro-planning", "claude-balanced", "gpt-best", "local-best"],
            "research": ["gemini-pro-research", "claude-best", "gpt-best", "local-analytical"],
            "thinking": ["gemini-flash-thinking", "claude-balanced", "gpt-best", "local-best"],
            "fast": ["gemini-flash-fast", "gpt-fast", "claude-fast", "local-fast"],
            "coding": ["local-coder", "claude-balanced", "gpt-best", "local-best"],
            "general": ["gemini-flash-fast", "claude-balanced", "gpt-best", "local-best"]
        }
    }
}