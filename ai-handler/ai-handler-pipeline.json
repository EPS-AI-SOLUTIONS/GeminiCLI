{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "name": "HYDRA AI Handler Pipeline",
  "version": "3.0.0",
  "description": "Comprehensive pipeline configuration for the 6-Step Swarm Protocol with 12 Witcher Agents and parallel execution via RunspacePool",
  "author": "HYDRA System",
  "updated": "2026-01-14",

  "architecture": {
    "type": "hybrid",
    "cloud_provider": "Google Gemini (dynamic)",
    "local_provider": "Ollama",
    "orchestration": "PowerShell RunspacePool",
    "module": "AgentSwarm.psm1 v3.0 (Unified)",
    "model_resolution": "dynamic_aliases"
  },

  "model_aliases": {
    "_comment": "Aliases resolved at runtime via Resolve-ModelAlias function",
    "gemini-pro-planning": "Best Gemini Pro for planning tasks",
    "gemini-pro-research": "Best Gemini Pro with grounding/search",
    "gemini-flash-thinking": "Best Gemini Flash for reasoning",
    "gemini-flash-fast": "Fastest Gemini Flash available"
  },

  "swarm_protocol": {
    "total_steps": 6,
    "execution_mode": "parallel",
    "fallback_mode": "sequential",
    "steps": [
      {
        "step": 1,
        "name": "Speculate",
        "description": "Gather research context from the web before planning",
        "provider": "google",
        "model": "gemini-flash-fast",
        "model_note": "Alias - resolved to latest fast flash model at runtime",
        "tools": ["google_search"],
        "timeout_ms": 30000,
        "retry_attempts": 2,
        "skip_if_offline": true,
        "output": "draftContext"
      },
      {
        "step": 2,
        "name": "Plan",
        "description": "Generate structured JSON task plan using deep thinking",
        "provider": "google",
        "model": "gemini-pro-planning",
        "model_note": "Alias - resolved to latest pro model at runtime",
        "tools": [],
        "timeout_ms": 60000,
        "retry_attempts": 3,
        "input": ["userPrompt", "draftContext"],
        "output": "planObject",
        "output_format": "json",
        "json_schema": {
          "type": "object",
          "required": ["thought_process", "tasks"],
          "properties": {
            "thought_process": { "type": "string" },
            "tasks": {
              "type": "array",
              "items": {
                "type": "object",
                "required": ["id", "agent", "instruction"],
                "properties": {
                  "id": { "type": "integer" },
                  "agent": { "type": "string", "enum": ["Geralt", "Yennefer", "Triss", "Jaskier", "Vesemir", "Ciri", "Eskel", "Lambert", "Zoltan", "Regis", "Dijkstra", "Philippa"] },
                  "instruction": { "type": "string" }
                }
              }
            }
          }
        }
      },
      {
        "step": 3,
        "name": "Execute",
        "description": "Parallel execution of agent tasks via RunspacePool",
        "execution_engine": "Invoke-ParallelSwarmExecution",
        "dispatcher": {
          "provider": "google",
          "model": "gemini-flash-fast",
          "model_note": "Alias - resolved at runtime",
          "purpose": "Generate system prompts for each agent"
        },
        "executor": {
          "provider": "ollama",
          "model_selection": "dynamic",
          "purpose": "Run agent tasks locally"
        },
        "concurrency": {
          "max_parallel": 5,
          "max_local": 2,
          "max_cloud": 4
        },
        "timeout_ms": 120000,
        "input": ["planObject.tasks"],
        "output": "agentResults"
      },
      {
        "step": 4,
        "name": "Synthesize",
        "description": "Merge all agent results into coherent final answer",
        "provider": "google",
        "model": "gemini-pro-planning",
        "model_note": "Alias - resolved at runtime",
        "tools": [],
        "timeout_ms": 60000,
        "retry_attempts": 2,
        "input": ["userPrompt", "agentResults"],
        "output": "finalAnswer"
      },
      {
        "step": 5,
        "name": "Log",
        "description": "Create concise session summary for daily log",
        "provider": "google",
        "model": "gemini-flash-fast",
        "model_note": "Alias - resolved at runtime",
        "tools": [],
        "timeout_ms": 15000,
        "retry_attempts": 1,
        "input": ["userPrompt", "planObject.thought_process", "agentResults", "finalAnswer"],
        "output": "sessionSummary",
        "persist_to": ".serena/memories/task_log_{date}.md"
      },
      {
        "step": 6,
        "name": "Archive",
        "description": "Save full session transcript to Markdown",
        "provider": "none",
        "tools": [],
        "input": ["userPrompt", "planObject", "agentResults", "finalAnswer"],
        "output": "sessionArchive",
        "persist_to": ".serena/memories/sessions/Session-{timestamp}.md",
        "format": "markdown"
      }
    ]
  },

  "agents": {
    "total": 12,
    "school": "School of the Wolf",
    "roster": [
      {
        "name": "Geralt",
        "persona": "White Wolf",
        "specialization": "Security/Ops",
        "model": "llama3.2:3b",
        "focus": ["system_commands", "security_checks", "execution", "defense"],
        "priority_tasks": ["chmod", "permissions", "firewall", "authentication"],
        "memory_file": ".serena/memories/Geralt.md"
      },
      {
        "name": "Yennefer",
        "persona": "Sorceress",
        "specialization": "Architecture/Code",
        "model": "qwen2.5-coder:1.5b",
        "focus": ["code_implementation", "architecture", "complex_logic", "structure"],
        "priority_tasks": ["class_design", "api_design", "refactoring", "patterns"],
        "memory_file": ".serena/memories/Yennefer.md"
      },
      {
        "name": "Triss",
        "persona": "Healer",
        "specialization": "QA/Testing",
        "model": "qwen2.5-coder:1.5b",
        "focus": ["testing", "validation", "bug_fixes", "quality"],
        "priority_tasks": ["unit_tests", "integration_tests", "debugging", "fixes"],
        "memory_file": ".serena/memories/Triss.md"
      },
      {
        "name": "Jaskier",
        "persona": "Bard",
        "specialization": "Docs/Communication",
        "model": "llama3.2:3b",
        "focus": ["documentation", "logs", "reports", "user_communication"],
        "priority_tasks": ["readme", "comments", "changelog", "user_guides"],
        "memory_file": ".serena/memories/Jaskier.md"
      },
      {
        "name": "Vesemir",
        "persona": "Mentor",
        "specialization": "Mentoring/Review",
        "model": "llama3.2:3b",
        "focus": ["code_review", "best_practices", "teaching", "wisdom"],
        "priority_tasks": ["review", "standards", "legacy_code", "mentoring"],
        "memory_file": ".serena/memories/Vesemir.md"
      },
      {
        "name": "Ciri",
        "persona": "Prodigy",
        "specialization": "Speed/Quick",
        "model": "llama3.2:1b",
        "focus": ["fast_tasks", "one_liners", "simple_operations", "speed"],
        "priority_tasks": ["quick_fix", "rename", "format", "simple_query"],
        "memory_file": ".serena/memories/Ciri.md"
      },
      {
        "name": "Eskel",
        "persona": "Pragmatist",
        "specialization": "DevOps/Infrastructure",
        "model": "llama3.2:3b",
        "focus": ["ci_cd", "deployment", "infrastructure", "automation"],
        "priority_tasks": ["docker", "kubernetes", "github_actions", "terraform"],
        "memory_file": ".serena/memories/Eskel.md"
      },
      {
        "name": "Lambert",
        "persona": "Skeptic",
        "specialization": "Debugging/Profiling",
        "model": "qwen2.5-coder:1.5b",
        "focus": ["debugging", "profiling", "performance", "optimization"],
        "priority_tasks": ["memory_leak", "bottleneck", "profiler", "trace"],
        "memory_file": ".serena/memories/Lambert.md"
      },
      {
        "name": "Zoltan",
        "persona": "Craftsman",
        "specialization": "Data/Database",
        "model": "llama3.2:3b",
        "focus": ["data_operations", "database", "migrations", "queries"],
        "priority_tasks": ["sql", "schema", "migration", "backup", "restore"],
        "memory_file": ".serena/memories/Zoltan.md"
      },
      {
        "name": "Regis",
        "persona": "Sage",
        "specialization": "Research/Analysis",
        "model": "phi3:mini",
        "focus": ["deep_analysis", "research", "algorithms", "theory"],
        "priority_tasks": ["algorithm", "complexity", "research", "analysis"],
        "memory_file": ".serena/memories/Regis.md"
      },
      {
        "name": "Dijkstra",
        "persona": "Spymaster",
        "specialization": "Planning/Strategy",
        "model": "llama3.2:3b",
        "focus": ["strategic_planning", "coordination", "big_picture", "orchestration"],
        "priority_tasks": ["roadmap", "planning", "coordination", "strategy"],
        "memory_file": ".serena/memories/Dijkstra.md"
      },
      {
        "name": "Philippa",
        "persona": "Strategist",
        "specialization": "Integration/API",
        "model": "qwen2.5-coder:1.5b",
        "focus": ["external_apis", "integrations", "connections", "protocols"],
        "priority_tasks": ["rest_api", "graphql", "webhooks", "oauth"],
        "memory_file": ".serena/memories/Philippa.md"
      }
    ],
    "model_mapping": {
      "fastest": ["Ciri"],
      "analytical": ["Regis"],
      "code_specialists": ["Yennefer", "Triss", "Lambert", "Philippa"],
      "general_purpose": ["Geralt", "Jaskier", "Vesemir", "Eskel", "Zoltan", "Dijkstra"]
    }
  },

  "providers": {
    "google": {
      "enabled": true,
      "models": {
        "_note": "These are aliases - resolved dynamically at runtime",
        "planner": "gemini-pro-planning",
        "speculator": "gemini-flash-fast",
        "dispatcher": "gemini-flash-fast",
        "synthesizer": "gemini-pro-planning",
        "researcher": "gemini-pro-research",
        "thinker": "gemini-flash-thinking"
      },
      "features": ["deep_thinking", "google_search", "code_execution"],
      "rate_limits": {
        "requests_per_minute": 60,
        "tokens_per_minute": 1000000
      }
    },
    "ollama": {
      "enabled": true,
      "host": "http://localhost:11434",
      "models": {
        "fast": "llama3.2:1b",
        "general": "llama3.2:3b",
        "coder": "qwen2.5-coder:1.5b",
        "analytical": "phi3:mini"
      },
      "features": ["local_execution", "offline_mode", "privacy"],
      "concurrency_limit": 2
    },
    "anthropic": {
      "enabled": true,
      "fallback_model": "claude-3-5-sonnet-latest",
      "priority": 2
    },
    "openai": {
      "enabled": true,
      "fallback_model": "gpt-4o",
      "priority": 3
    }
  },

  "failover": {
    "enabled": true,
    "chain": ["google", "anthropic", "openai", "ollama"],
    "strategy": "sequential",
    "offline_fallback": "ollama",
    "max_retries_per_provider": 2,
    "task_fallback_chains": {
      "_comment": "Use Get-ModelForTask to resolve these at runtime",
      "planning": ["gemini-pro-planning", "claude-balanced", "gpt-best", "local-best"],
      "research": ["gemini-pro-research", "claude-best", "gpt-best", "local-analytical"],
      "thinking": ["gemini-flash-thinking", "claude-balanced", "gpt-best", "local-best"],
      "fast": ["gemini-flash-fast", "gpt-fast", "claude-fast", "local-fast"],
      "coding": ["local-coder", "claude-balanced", "gpt-best", "local-best"],
      "general": ["gemini-flash-fast", "claude-balanced", "gpt-best", "local-best"]
    }
  },

  "concurrency": {
    "execution_engine": "RunspacePool",
    "configuration": {
      "max_concurrent_total": 5,
      "max_concurrent_local": 2,
      "max_concurrent_cloud": 4,
      "queue_type": "ConcurrentQueue",
      "job_tracking": "ConcurrentDictionary"
    },
    "performance": {
      "sequential_baseline": "4 agents x 10s = 40s",
      "parallel_optimized": "4 agents x 10s = ~12s",
      "improvement": "70%"
    }
  },

  "memory": {
    "enabled": true,
    "base_path": ".serena/memories",
    "agent_memory": {
      "format": "markdown",
      "per_agent": true,
      "rebase_probability": 0.1,
      "rebase_model": "llama3.2:3b"
    },
    "session_logging": {
      "daily_log": "task_log_{YYYY-MM-DD}.md",
      "full_archive": "sessions/Session-{YYYYMMdd-HHmmss}.md"
    },
    "persistence": {
      "enabled": true,
      "cleanup_interval_days": 30
    }
  },

  "security": {
    "god_mode": {
      "enabled": true,
      "description": "Agents have full system access for task execution",
      "restrictions": ["no_hardcoded_secrets", "no_git_commits_of_env"]
    },
    "api_keys": {
      "storage": "environment_variables",
      "display": "masked_first_15_chars"
    }
  },

  "modes": {
    "standard": {
      "concurrency": 5,
      "safety_blocking": true,
      "retries": 3,
      "timeout_s": 60
    },
    "yolo": {
      "concurrency": 10,
      "safety_blocking": false,
      "retries": 1,
      "timeout_s": 15,
      "activation": "./_launcher.ps1 -Yolo"
    }
  },

  "mcp_integration": {
    "enabled": true,
    "tools": {
      "serena": {
        "commands": ["find_symbol", "read_file", "write_memory"],
        "purpose": "Code navigation and memory management"
      },
      "desktop_commander": {
        "commands": ["start_process", "read_file", "write_file", "list_directory"],
        "purpose": "File system and shell operations"
      },
      "playwright": {
        "commands": ["browser_navigate", "browser_snapshot"],
        "purpose": "Web interaction and verification"
      }
    }
  },

  "exported_functions": {
    "total": 16,
    "categories": {
      "agent_swarm": ["Invoke-AgentSwarm"],
      "utility": ["Get-AgentMemory", "Save-AgentMemory", "Get-AgentModel"],
      "prompt_optimization": ["Optimize-PromptAuto", "Get-PromptComplexity"],
      "queue_management": [
        "Add-ToSmartQueue",
        "Add-BatchToSmartQueue",
        "Get-QueueStatus",
        "Get-SmartQueueStatus",
        "Clear-SmartQueue",
        "Clear-QueueResults",
        "Get-QueueResults"
      ],
      "parallel_execution": [
        "Start-QueueProcessor",
        "Invoke-ParallelClassification",
        "Invoke-ParallelSwarmExecution"
      ]
    }
  },

  "diagnostics": {
    "health_check": "hydra_health",
    "config_check": "hydra_config",
    "queue_status": "Get-QueueStatus",
    "logging": {
      "level": "INFO",
      "format": "json_in_production"
    }
  }
}
